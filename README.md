# Предсказание затрат времени на проведение анализов при производстве БАД

## *Описание проекта*
При работе лаборатории выходного контроля промышленного предприятия по производству БАД было накоплено большое количество информации в виде текстовых протоколов, содержащих даты начала и окончания анализов, а также проанализированные компоненты. Возникла идея провести статистическую обработку имеющихся данных с целью:
+ прогнозирования времени анализа различных наименований продукции;
+ получения информации о наиболее долгих анализах с целью изучения возможности оптимизации методов их проведения;
+ построения модели способной прогнозировать время на анализ всех компонентов продукта на основе информации о его составе.

### <a id="content">*Содержание*</a>

[Описание данных](#data)

[Модель для поиска долгих анализов](#linear_regression)

[Модель для прогнозирования продолжительности анализа](#boosting)

## <a id="data">*Данные*</a>
Данные были собраны из рабочих протоколов выходного контроля аналитической лаборатории. Протоколы сначала сконвертировали из .doc и .docx файлов в .html формат с помощью LibreOffice. Затем выбрали нужную информацию с помощью HTMLParser.

>Таким образом изначально в датасете были колонки:
>+ номер протокола
>+ дата оформления протокола
>+ дата производства серии продукта
>+ дата поступления образца на анализ в лабораторию
>+ закодированное наименование продукта
>+ коды компонентов, которые анализировали в этой серии продукции

Таким образом было собрано 24342 записи.

В процессе предварительной обработки этих данных были сгенерированы дополнительные признаки ([тетрадка](https://github.com/Na-ta-ly/Analysis-duration/blob/main/Data%20preprocessing.ipynb)).

Из колонок с датами оформления протокола, датами поступления и датами производства получено ***количество дней, затраченное на проведение всех анализов серии продукта***. Из-за изменения формата протоколов, в некоторых из них указывалась дата поступления образца, а в других - дата производства серии продукта. По установленному на предприятии регламенту образцы поступали в лабораторию в день производства, поэтому эти даты взаимозаменяемы. Записи, для которых не удалось вычислить этот показатель, были удалены.

Для оценки загруженности лаборатории было посчитано ***количество других образцов***, находившихся в работе на дату поступления на анализ каждого образца.

Кроме того был отдельно выделен год проведения анализов. Эти данные использовались для анализа статистики работы лаборатории.

---

Далее был проведен разведочный анализ данных ([тетрадка](https://github.com/Na-ta-ly/Analysis-duration/blob/main/EDA.ipynb)), в ходе которого отмечено:
+ Изначально предполагалось, что в графе нужного компонента будет стоять 1 при проведении анализа. Однако в некоторых компонентах получилось значение 2. После изучения этих протоколов, оказалось, что в некоторых случаях анализ по этому компоненту выполнялся дважды. Поэтому такие значения было принято решение оставить без изменения.
+ В 2018 году был выявлен резкий скачок в количестве анализов.
+ Как и ожидалось, наблюдается значительная корреляция между количеством дней на анализы и числом образцов.
+ Было обнаружено 6% анализов, длившихся аномально долго. Их отбросили для получения устойчивой модели.
+ Часть образцов имеет аномально много "соседей" на анализ. Их также исключили из выборки, так как они преимущественно наблюдались в 2018 году, когда режим работы лаборатории был аномальным.
+ Дополнительно из выборки исключили протоколы за 2013 и 2023 годы, в связи с их малым количеством.

Итого получилось 21675 записей.

*Связь между сгенерированными признаками*

![Correlation matrix](pics/correlation.png)

Сгруппировав данные по продуктам, мы получили данные о средних сроках анализа этих продуктов. Эти данные можно использовать напрямую для оценки сроков выполнения анализов и планирования работы лаборатории.

## <a id="linear_regression">*Построение модели регрессии для поиска долгих анализов*</a>
[К содержанию](#content)
### *Описание работы*

Задача по выявлению наиболее долгих анализов решена в [тетрадке](https://github.com/Na-ta-ly/Analysis-duration/blob/main/Models.ipynb).

Данные были разбиты на тренировочную и тестовую подвыборки в соотношении 7:3.

Затем была построена простая линейная регрессия, прогнозирующая количество дней на анализ в зависимости от заполненности граф компонентов и количества других образцов в лаборатории.

Эта модель была выбрана из-за легкой интерпретируемости полученных коэффициентов. Чем больше значение перед компонентом, тем больший вклад он вносит в суммарное время анализа, а следовательно, методику определения этого компонента необходимо изучить на предмет возможности ее оптимизации.

При анализе полученных результатов было выявлено, что методики в начале списка действительно трудоемкие и длительные. Это доказало применимость подобного метода для решения задач такого типа.

## <a id="boosting">*Построение модели градиентного бустинга для прогнозирования продолжительности анализа*</a>
[К содержанию](#content)
### *Описание работы*

Задача по выявлению наиболее долгих анализов решена в [тетрадке](https://github.com/Na-ta-ly/Analysis-duration/blob/main/Models.ipynb).

Данные, также как и для прошлой модели, были разбиты на тренировочную и тестовую подвыборки в соотношении 7:3.

Теперь строили модель GradientBoostingRegressor с подбором оптимальных параметров с помощью GridSearchCV. Для наших данных оптимальными оказались:
+ learning_rate=0.1,
+ n_estimators=300,
+ max_depth=10,
+ min_samples_split=2.

При оценке модели было получено значение MAE на тестовой выборке 5.73 дней, при средней продолжительности анализов 19.31 дня.

К сожалению, на момент проведения работы, модель внедрить в использование было невозможно с связи с отсутствием электронной регистрации поступающих на контроль образцов, но это возможно после запуска в лаборатории какой-либо базы данных с этой информацией.
